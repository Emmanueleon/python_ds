{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solucionar problemas con archivos csv\n",
    "---\n",
    "\n",
    "CSV significa **valores separados por comas**. Sin embargo, un archivo CSV no tiene que usar solo una coma como **delimitador**; se puede usar cualquier carácter. \n",
    "\n",
    "A veces pueden aparecer como archivos `.tsv` o `.tab` (también conocidos como archivos TSV) además de `.csv`.\n",
    "\n",
    "Existen formas de lidiar con estos problemas: \n",
    "1. Usar el argumento `sep`. \n",
    "2. Indicar nombre de encabezados con `header = None` y `name=`. \n",
    "3. Renombrar encabezados con `header = None`y `rename()`. \n",
    "4. Indicar tipo de decimales con el argumento `decimal = `. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/gpp_modified.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Uso de tipo de separador, por defecto \",\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/datasets/gpp_modified.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/gpp_modified.csv'"
     ]
    }
   ],
   "source": [
    "## Uso de tipo de separador, por defecto \",\"\n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicar nombre de encabezados \n",
    "column_names = [\n",
    "    'country',\n",
    "    'name',\n",
    "    'capacity_mw',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'primary_fuel',\n",
    "    'owner'\n",
    "    ]\n",
    "\n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renombrar encabezado\n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', header=None)\n",
    "\n",
    "data = data.rename(columns = {0: \"country\",1: \"name\", 2:\"capacity_mw\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicar el tipo de decimal \n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer archivos excel\n",
    "---\n",
    "\n",
    "Pandas proporciona la función `read_excel()` para leer archivos Excel \n",
    "\n",
    "Por defecto, esta función carga la primera hoja, pero un archivo Excel puede contener varias hojas. Para tal caso utilizar el parámetro `sheet_name=` y especificar el nombre o el número de la hoja que queremos seleccionar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abrir archivo excel\n",
    "### Con nombre de la hoja de cálculo \n",
    "df = pd.read_excel('/datasets/product_reviews.xlsx', sheet_name='reviewers')\n",
    "\n",
    "### Con número de la hoja de cálculo \n",
    "df = pd.read_excel('/datasets/product_reviews.xlsx', sheet_name=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de los datos\n",
    "---\n",
    "\n",
    "Echar un vistazo a tus datos es útil cuando empiezas a trabajar con un nuevo dataset porque te ayudan a plantear las primeras preguntas que debes explorar. Algunos de los atributos y métodos incluyen: \n",
    "\n",
    "- `info()`. Imprime información general sobre el DataFrame\n",
    "- `shape()`. Devuelve tanto el número de filas como el número de columnas en el dataset. \n",
    "- `sample()`. Selecciona filas aleatorias del DataFrame en lugar de filas consecutivas del principio o del final del DataFrame. \n",
    "- `describe()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estructura del dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la siguiente información: \n",
    "\n",
    "- El número de filas (RangeIndex: __ entries);\n",
    "- El número de columnas (total __ columns);\n",
    "- El nombre de cada columna (Column);\n",
    "- El número de valores de cada columna que no están ausentes (Non-Null Count);\n",
    "- El tipo de datos de cada columna (Dtype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Almacenar número de filas y columnas como variables\n",
    "n_rows, n_cols = df.shape\n",
    "\n",
    "print(f\" El dataframe tiene {n_rows} filas y {n_cols} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `shape` devuelve una **tupla** como salida. \n",
    "\n",
    "Una tupla es un tipo de datos similar a una lista de Python en términos de indexación, objetos anidados y repetición. Sin embargo, la principal diferencia entre ambas es que una tupla Python es inmutable (no puede modificarse), mientras que una lista Python es mutable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder tener una mejor visión del dataframe, podemos combinar el método `info()` y otro métodos como `head()` o `tail()`. Sin embargo,para poder observar una mejor muestra de los datos que se encuentran en el dataframe y no solo los encabezados y la última parte se puede usar el método `sample()`. Si quiero que haya repetibilidad en mi aleatoriedad agregar el argumento `random_satet()` y establecer y algún valor entero de tu elección (cualquier número entero entre 0 y 4294967295)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encabezados\n",
    "print(data.head(10))\n",
    "\n",
    "## Parte final \n",
    "print(data.tail(10))\n",
    "\n",
    "## Aleatorio\n",
    "print(data.sample(10))\n",
    "\n",
    "## Aleatoriedad establecida\n",
    "print(data.sample(10, random_state= 1989))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `describe()` es muy útil para obtener información sobre las columnas numéricas de tus datos. La salida incluye estadísticas de resumen.   \n",
    "\n",
    "Es aconsejable que además, el análisis se acompañe de visualizaciones de datos para obtener una imagen completa, , ya que es posible que sus estructuras sean muy diferentes aunque tengan estadísticas resumidas similares (como el cuarteto de Anscombe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Método describe()\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera predeterminada, se ignoran las columnas no numéricas. Para poder incluir otro tipo de columnas no numéricas se utiliza el parámetro `include =` con el tipo de datos que queremos añadir p.e, `object` u añadir todas las columnas `all`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajar con valores ausentes y duplicados\n",
    "---\n",
    "\n",
    "### Contar valores ausentes\n",
    "Una buena manera de empezar a comprobar los valores ausentes es llamar al método `info()` de tu DataFrame. Los valores nulos son valores ausentes, mientras que los no nulos son valores no ausentes. \n",
    "\n",
    "Una vez identificado el número de observaciones podemos determinar el número de valores ausentes con `isna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determinar la información del dataframe\n",
    "data.info()\n",
    "\n",
    "## Contar el número de valores ausentes de cada columna\n",
    "data.isna().sum()\n",
    "\n",
    "## Contar el número de valores ausentes totales\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción es con el método `value_counts()`, que devuelve la cantidad de veces que cada valor único aparece en esa columna. Este método es conveniente utilizarlo sobre una solo columna o *series*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conocer el número de valores únicos para la columna source\n",
    "print(df_logs['source'].value_counts(dropna=False)) # drop_na=False permite contar el número de Nas en la columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida se ordena en orden descendente según el recuento de cada valor. Alternativamente, podemos ordenar la salida alfabéticamente según los nombres de los valores. Para hacerlo, podemos utilizar el método `sort_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ordenar el resultado de acuerdo con el index y no de acuerdo con los valores de la columna\n",
    "print(df_logs['source'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Dataframes con NaNs\n",
    "\n",
    "Para examinar las filas auseentes del dataframe, una de las maneras es utilizar el método `is.na()`.  El resultado genera una serie con los valores ausente `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtra los valores con NaNs\n",
    "print(df_logs[df_logs['source'].isna()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sin embargo, a veces no es eso lo que nos convien. Para ello resulta más útil combinar `~ `con `isna()` para filtrar las filas con valores ausentes. La adición del símbolo de tilde (~), invierte el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtra los valores sin NaNs\n",
    "print(df_logs[~df_logs['source'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible filtrar un dataframe a partir de **múltiples condiciones de filtrado**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el df donde no haya valores ausentes en la columna \"email\" \n",
    "# y que solo sean valores de email de la columna source\n",
    "print(df_logs[(~df_logs['email'].isna()) & (df_logs['source'] == 'email')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de filtrado anterior consta de dos partes:\n",
    "\n",
    "1. `(~df_logs['email'].isna())` devuelve una serie de booleanos donde `True` indica que no falta ningún valor en la columna `'email'`.\n",
    "\n",
    "2. `(df_logs['source'] == 'email')` devuelve una serie de booleanos, donde `True` indica que `'source'` tiene `'email'` como valor, y `False` indica lo contrario.\n",
    "\n",
    "3. Comprobamos dos series de booleanos para ver dónde ambas condiciones devuelven `True`. Utilizamos el símbolo `&` para representar el operador lógico `and`. Las filas que cumplen ambas condiciones (es decir, que cumplen la primera condición y la segunda) se incluyen en el resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rellenar los valores categóricos ausentes\n",
    "\n",
    "Como recordatorio, las **variables categóricas** o **cualitativas** representan un conjunto de valores posibles que puede tener una observación particular. Es posible que tengan un orden en particular, por lo que serían **ordinales** o pueden no tener un orden en particular, por lo que serían **nominales**. \n",
    "\n",
    "Podemos sustituir los valores ausentes de las columnas con **valores por defecto** por ejemplo, una cadena vacía `''` . Esto lo podemos realizar con el método `fillna()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sustituir valores ausentes\n",
    "df_logs['email'] = df_logs[\"email\"].fillna(value= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar `fillna()` no es la única forma en que podemos rellenar los valores ausentes con cadenas vacías. También podemos hacerlo directamente al leer los datos mediante `read_csv()` utilizando el parámetro `keep_default_na = False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar el dataset haciendo que en vez de que sean NaN = TRUE sea FALSE\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "print(df_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Nota:</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Ten en cuenta que establecer `keep_default_na=False` convierte todos los valores ausentes **en cadenas vacías**, incluso para columnas numéricas. Esto hace que las columnas numéricas se lean como cadenas cuando tienen valores ausentes.   \n",
    "\n",
    "Así que asegúrate de usar solo `keep_default_na=False` cuando desees que todos los valores ausentes en cada columna se lean como cadenas vacías.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible que, querramos sustituir los valores de defecto por algún otro valor. En tal caso es útil emplear el método `replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remplazar el valor de defecto \"\" por otro valor\n",
    "df_logs['source'] = df_logs[\"source\"].replace(\"\", \"email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rellenar los valores ausentes cualitativos \n",
    "\n",
    "Como recordatorio, las variables **cuantitativas** tienen valores numéricos que podemos usar para cálculos aritméticos, por ejemplo, la altura, el peso, la edad y los ingresos. En Python, estos valores tienden a almacenarse como números enteros o flotantes.\n",
    "\n",
    "Debido a que queremos hacer cálculos numéricos con estas columnas, no podemos rellenar esos valores con cadenas como `'Unknown'` o `''`. En su lugar, debemos rellenarlos con valores representativos apropiados. Para estos valores se suele utilizar la **media** o la **mediana** del conjunto de datos.\n",
    "\n",
    "La elección entre media o mediana dependerá de la uniformidad de los valores, es decir, de su **distribución**. \n",
    "\n",
    "\n",
    "Para rellenar los valores ausentes, podemos seguir estos pasos:\n",
    "\n",
    "1. Determina la distribución de los datos.\n",
    "\n",
    "2. Si no hay valores atípicos significativos, calcula la media utilizando el método `mean()`.\n",
    "\n",
    "3. Si tus datos tienen valores atípicos significativos, calcula la mediana utilizando el método `median()`.\n",
    "\n",
    "4. Reemplaza los valores ausentes con la media o la mediana utilizando el método `fillna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remplazar el promedio \n",
    "### Determinar el promedio \n",
    "age_avg = analytics_data['age'].mean()\n",
    "print(\"Mean age:\", age_avg)\n",
    "\n",
    "### Remplazar la columna con los valores promedio\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Nota:</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "También vale la pena señalar que a veces no necesitamos rellenar los valores ausentes en absoluto.  Por ejemplo, si solo falta una pequeña parte de tus datos, y los datos ausentes son aleatorios, podría ser buena idea dejar los valores como NaN, en cuyo caso simplemente no se incluirían en ningún cálculo numérico.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestión de duplicados\n",
    "\n",
    "Otro de los problemas comunes en la etapa de procesamiento de datos en las bases de datos son los valores duplicados. \n",
    "\n",
    "Hay dos técnicas que funcionan para encontrar datos duplicados:\n",
    "\n",
    "1. Podemos utilizar el método `duplicated()` junto con `sum()` para obtener el número de valores duplicados en una sola columna o filas duplicadas en un DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columna booleana con False si no es duplicada y True si lo es \n",
    "print(df.duplicated())\n",
    "\n",
    "## Conteo de las filas duplicadas\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "## Conocer las filas duplicadas\n",
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Podemos utilizar el método `value_counts()`. Este método identifica todos los valores unívocos en una columna y calcula cuántas veces aparece cada uno. Podemos aplicar este método a los Series para obtener los pares valor-frecuencia en orden descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conocer el número de veces que determinada fila es similar\n",
    "print(df['col_1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que mediante este método solo se inspecciona la columna seleccionada, puede que no sea un **duplicado explicito** y solo se repita el valor de dicha columna y no de las subsecuentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de que existan **filas completamente duplicadas**, se pueden tratar utilizando el método `drop_duplicates()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminar filas duplicadas explícitas\n",
    "print(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si solo deseas considerar duplicados en una (o algunas) de las columnas en lugar de filas completamente duplicadas, puedes usar el parámetro `subset=`. Pásale el nombre de la columna (o la lista de nombres de columna) donde deseas buscar duplicados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminar filas seleccionadas \n",
    "print(df.drop_duplicates(subset='col_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto eliminará las columnas con valores similares, pero puede eliminar otras columnas donde los valores sean diferentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que después de eliminar los duplicados, tenemos que llamar al método `reset_index()` con el parámetro `drop=True`. Esto nos permite arreglar la indexación y eliminar el índice antiguo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen casos en donde existan **duplicados implícitos** y puedan existir *typos*. Para ello, la forma más sencilla de manejar entradas duplicadas como estas es homogeneizar los términos de acuerdo con las buenas prácticas de programación. \n",
    "\n",
    "Por ejemplo, hacer que todas las letras de cadenas estén en minúsculas, utilizando el método `lower()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convertie los strings en mínusculas\n",
    "print(df['col_1'].str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de `df['col_1']`, tenemos `.str`, que nos permite aplicar métodos de cadena directamente a la columna. Esto es necesario para poder aplicar el método `lower()` en el paso siguiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que el cambio se preserve, ten en cuenta que se debe **sustituir** la columna original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sustituir la columna col_1\n",
    "df['col_1'] = df['col_1'].str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción para cambiar duplicados, sin necesidad de cambiar mayúsculas por minúsculas, es cambiar todas las apariciones específicas de una columnas por otro string, utilizando el método `replace()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remplazar un string por otro\n",
    "df['category_modified'] = df['category'].str.replace('tbc', 'baby care')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no estás seguro de cuál es el mejor enfoque, siempre puedes conservar la columna original y crear una nueva columna adicional, con las cadenas modificadas. Por ejemplo, podrías guardar el resultado de la sustitución en la columna `'item'` en una nueva columna llamada `'item_modified'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creación de nueva columa \n",
    "df['category_modified'] = df['category'].str.replace('tbc', 'baby care')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente otra aproximación para poder cambiar un valor específico es utilizar el método `loc[]`. Para ello: \n",
    "\n",
    "1. Buscamos la fila que contiene el valor que queremos sustituir. \n",
    "2. Pasamos el índice y el nombre de columna adecuados a `loc[]`, y utiliza el signo `=` para establecer el valor deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo en conjunto\n",
    "\n",
    "## Determinar el promedio\n",
    "avg_per_category = df.groupby('category')['price'].mean()\n",
    "\n",
    "## Extraer del dataframe\n",
    "mean_val = avg_per_category[2]\n",
    "\n",
    "## Sustituir mediante loc[]\n",
    "df.loc[7,\"price\"] = mean_val# escribe tu código aquí\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de datos\n",
    "---\n",
    "\n",
    "### Atributo index\n",
    "Los objetos Series y DataFrame en pandas siempre tienen índices que se almacenan en el atributo index. Cada vez que creas un Series o un DataFrame, su atributo de index se crea automáticamente con valores por defecto si no especificas los valores del índice.\n",
    "\n",
    "Existen dos maneras de establecer valores de índice:\n",
    "\n",
    "- Pasar los valores del índice al parámetro `index=` al crear un DataFrame o un Series.\n",
    "- Asignar los valores del índice al atributo `index` de un DataFrame o Series existente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     Pacific\n",
      "B    Atlantic\n",
      "C      Indian\n",
      "D    Southern\n",
      "E      Arctic\n",
      "dtype: object\n",
      "\n",
      "1     Pacific\n",
      "2    Atlantic\n",
      "3      Indian\n",
      "4    Southern\n",
      "5      Arctic\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Manera 1: Pasar los valores al parámetro index\n",
    "oceans = pd.Series(['Pacific', 'Atlantic', 'Indian', 'Southern', 'Arctic'],\n",
    "                   index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "print(oceans)\n",
    "print()\n",
    "\n",
    "## Manera 2: Asignar los valores al atributo index\n",
    "oceans = pd.Series(['Pacific', 'Atlantic', 'Indian', 'Southern', 'Arctic'])\n",
    "\n",
    "oceans.index = [1, 2, 3, 4, 5]\n",
    "print(oceans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de los DataFrames, existe otra forma de establecer los valores del índice mediante el método `set_index()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          flower                          insect\n",
      "state                                                           \n",
      "Alabama                 Camellia               Monarch butterfly\n",
      "Alaska             Forget-me-not  Four-spotted skimmer dragonfly\n",
      "Arizona   Saguaro cactus blossom          Two-tailed swallowtail\n",
      "Arkansas           Apple blossom              European honey bee\n",
      "\n",
      "Index(['Alabama', 'Alaska', 'Arizona', 'Arkansas'], dtype='object', name='state')\n"
     ]
    }
   ],
   "source": [
    "states  = ['Alabama', 'Alaska', 'Arizona', 'Arkansas']\n",
    "flowers = ['Camellia', 'Forget-me-not', 'Saguaro cactus blossom', 'Apple blossom']\n",
    "insects = ['Monarch butterfly', 'Four-spotted skimmer dragonfly', 'Two-tailed swallowtail', 'European honey bee']\n",
    "index   = ['state 1', 'state 2', 'state 3', 'state 4']\n",
    "\n",
    "df = pd.DataFrame({'state': states, 'flower': flowers, 'insect': insects}, index=index)\n",
    "df = df.set_index('state') # reemplazar el índice\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originalmente, nuestros índices eran números de estado: 'state 1', 'state 2' etc. Después, los sustituimos por los valores de la columna 'state'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no quieres que el índice tenga un nombre, puedes eliminarlo estableciendo el atributo index_name de un DataFrame a None. Así es como puedes hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          flower                          insect\n",
      "Alabama                 Camellia               Monarch butterfly\n",
      "Alaska             Forget-me-not  Four-spotted skimmer dragonfly\n",
      "Arizona   Saguaro cactus blossom          Two-tailed swallowtail\n",
      "Arkansas           Apple blossom              European honey bee\n",
      "\n",
      "Index(['Alabama', 'Alaska', 'Arizona', 'Arkansas'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "states  = ['Alabama', 'Alaska', 'Arizona', 'Arkansas']\n",
    "flowers = ['Camellia', 'Forget-me-not', 'Saguaro cactus blossom', 'Apple blossom']\n",
    "insects = ['Monarch butterfly', 'Four-spotted skimmer dragonfly', 'Two-tailed swallowtail', 'European honey bee']\n",
    "index   = ['state 1', 'state 2', 'state 3', 'state 4']\n",
    "\n",
    "df = pd.DataFrame({'state': states, 'flower': flowers, 'insect': insects}, index=index)\n",
    "df = df.set_index('state')\n",
    "\n",
    "df.index.name = None\n",
    "print(df)\n",
    "print()\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexación \n",
    "Ahora vamos a hablar de **indexación**. La terminología puede ser confusa, así que ten en cuenta estas definiciones:\n",
    "\n",
    "- Index (índice): un componente de un Series o DataFrame, accesible mediante el atributo `index`.\n",
    "- Indexing (indexación): el proceso de acceder a los valores de un Series o DataFrame utilizando sus índices.\n",
    "  \n",
    "Es posible utilizar el atributo `loc[]` para acceder a los elementos del DataFrame utilizando los valores de los índices y los nombres de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         flower                  insect\n",
      "state 1                Camellia       Monarch butterfly\n",
      "state 3  Saguaro cactus blossom  Two-tailed swallowtail\n"
     ]
    }
   ],
   "source": [
    "# Filtrado mediante uso de índices\n",
    "## Creación listas para dataframe\n",
    "states  = ['Alabama', 'Alaska', 'Arizona', 'Arkansas']\n",
    "flowers = ['Camellia', 'Forget-me-not', 'Saguaro cactus blossom', 'Apple blossom']\n",
    "insects = ['Monarch butterfly', 'Four-spotted skimmer dragonfly', 'Two-tailed swallowtail', 'European honey bee']\n",
    "index   = ['state 1', 'state 2', 'state 3', 'state 4']\n",
    "\n",
    "df = pd.DataFrame({'state': states, 'flower': flowers, 'insect': insects}, index=index)\n",
    "\n",
    "## Filtrado\n",
    "filtered_df = df.loc[['state 1', 'state 3'], ['flower', 'insect']]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener un rango de índices para una **única columna o fila**, solo hay que especificar el primer y el último índice separados por un `:`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 1                  Camellia\n",
      "state 2             Forget-me-not\n",
      "state 3    Saguaro cactus blossom\n",
      "Name: flower, dtype: object\n",
      "\n",
      "flower             Camellia\n",
      "insect    Monarch butterfly\n",
      "Name: state 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Indexar una sola solumna\n",
    "print(df.loc['state 1': 'state 3', 'flower'])\n",
    "print() \n",
    "\n",
    "## Indexar una sola fila\n",
    "print(df.loc[\"state 1\", \"flower\":\"insect\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera, puedes seleccionar **múltiples columnas así como índices**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         flower                          insect\n",
      "state 1                Camellia               Monarch butterfly\n",
      "state 2           Forget-me-not  Four-spotted skimmer dragonfly\n",
      "state 3  Saguaro cactus blossom          Two-tailed swallowtail\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[\"state 1\": \"state 3\", \"flower\": \"insect\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar el método `iloc[]` es muy similar. La principal diferencia entre métodos, es que `loc[]` utiliza el índice y las _etiquetas_ de columnas para acceder a los elementos, mientras que `iloc[]` utiliza _enteros_ para designar las posiciones de los elementos que necesitas obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European honey bee\n"
     ]
    }
   ],
   "source": [
    "## Uso de iloc para seleccionar el elemento de la fila 4 y la columna 3\n",
    "print(df.iloc[3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera que con `loc[]`, podemos acceder a múltiples filas y/o columnas con `iloc[]` pasándole listas de sus posiciones o utilizando el slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                flower                          insect\n",
      "state 2  Forget-me-not  Four-spotted skimmer dragonfly\n",
      "state 4  Apple blossom              European honey bee\n",
      "\n",
      "                flower                          insect\n",
      "state 1       Camellia               Monarch butterfly\n",
      "state 2  Forget-me-not  Four-spotted skimmer dragonfly\n"
     ]
    }
   ],
   "source": [
    "## Indexación utilizando celdas específicas\n",
    "print(df.iloc[[1,3], [1,2]])\n",
    "print()\n",
    "\n",
    "## Indexación utilizando rangos\n",
    "print(df.iloc[0:2, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar al utilizar rangos no es necesario poner los índices entre corchetes `[]`. En cambio si vamos a definir celdas específicas se necesita definirlas con los corchetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usar `iloc[]` puede ser más conveniente si sabes que solo quieres ver las primeras filas o columnas, o cuando sabes el número exacto de fila o columna que necesitas. `iloc[]` también puede ser útil como un atajo para ahorrar tiempo al escribir nombres de columnas o etiquetas de índices.\n",
    "\n",
    "- Usar `loc[]` puede lograr una mejor legibilidad y comprensión de lo que tu código está haciendo, tanto para tus colegas que leen tu código como para tu yo del futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado personalizado mediante query()\n",
    "\n",
    "Para filtrar DataFrames utilizando operadores lógicos para crear una serie de Booleanos que llamaremos **máscara booleana** a partir de ahora. Esta máscara nos permitirá accesar a la condición que queremos al implementarla sobre el df original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establesco la condición y creo el df booleano (máscara)\n",
    "mask = df['jp_sales'] >= 1\n",
    "\n",
    "## Pongo al df la máscara booleana y selecciona aquellas columnas que em interesan\n",
    "print(df[mask][['name', 'jp_sales']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos realizar este mismo filtrado utilizando el método `query()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LA misma condición establecida previamente\n",
    "print(df.query(\"jp_sales > 1\")[['name', 'jp_sales']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
