{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solucionar problemas con archivos csv\n",
    "\n",
    "CSV significa **valores separados por comas**. Sin embargo, un archivo CSV no tiene que usar solo una coma como **delimitador**; se puede usar cualquier carácter. \n",
    "\n",
    "A veces pueden aparecer como archivos `.tsv` o `.tab` (también conocidos como archivos TSV) además de `.csv`.\n",
    "\n",
    "Existen formas de lidiar con estos problemas: \n",
    "1. Usar el argumento `sep`. \n",
    "2. Indicar nombre de encabezados con `header = None` y `name=`. \n",
    "3. Renombrar encabezados con `header = None`y `rename()`. \n",
    "4. Indicar tipo de decimales con el argumento `decimal = `. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uso de tipo de separador, por defecto \",\"\n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicar nombre de encabezados \n",
    "column_names = [\n",
    "    'country',\n",
    "    'name',\n",
    "    'capacity_mw',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'primary_fuel',\n",
    "    'owner'\n",
    "    ]\n",
    "\n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renombrar encabezado\n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', header=None)\n",
    "\n",
    "data = data.rename(columns = {0: \"country\",1: \"name\", 2:\"capacity_mw\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicar el tipo de decimal \n",
    "data = pd.read_csv('/datasets/gpp_modified.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer archivos excel\n",
    "\n",
    "Pandas proporciona la función `read_excel()` para leer archivos Excel \n",
    "\n",
    "Por defecto, esta función carga la primera hoja, pero un archivo Excel puede contener varias hojas. Para tal caso utilizar el parámetro `sheet_name=` y especificar el nombre o el número de la hoja que queremos seleccionar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abrir archivo excel\n",
    "### Con nombre de la hoja de cálculo \n",
    "df = pd.read_excel('/datasets/product_reviews.xlsx', sheet_name='reviewers')\n",
    "\n",
    "### Con número de la hoja de cálculo \n",
    "df = pd.read_excel('/datasets/product_reviews.xlsx', sheet_name=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de los datos\n",
    "Echar un vistazo a tus datos es útil cuando empiezas a trabajar con un nuevo dataset porque te ayudan a plantear las primeras preguntas que debes explorar. Algunos de los atributos y métodos incluyen: \n",
    "\n",
    "- `info()`. Imprime información general sobre el DataFrame\n",
    "- `shape()`. Devuelve tanto el número de filas como el número de columnas en el dataset. \n",
    "- `sample()`. Selecciona filas aleatorias del DataFrame en lugar de filas consecutivas del principio o del final del DataFrame. \n",
    "- `describe()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estructura del dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la siguiente información: \n",
    "\n",
    "- El número de filas (RangeIndex: __ entries);\n",
    "- El número de columnas (total __ columns);\n",
    "- El nombre de cada columna (Column);\n",
    "- El número de valores de cada columna que no están ausentes (Non-Null Count);\n",
    "- El tipo de datos de cada columna (Dtype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Almacenar número de filas y columnas como variables\n",
    "n_rows, n_cols = df.shape\n",
    "\n",
    "print(f\" El dataframe tiene {n_rows} filas y {n_cols} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `shape` devuelve una **tupla** como salida. \n",
    "\n",
    "Una tupla es un tipo de datos similar a una lista de Python en términos de indexación, objetos anidados y repetición. Sin embargo, la principal diferencia entre ambas es que una tupla Python es inmutable (no puede modificarse), mientras que una lista Python es mutable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder tener una mejor visión del dataframe, podemos combinar el método `info()` y otro métodos como `head()` o `tail()`. Sin embargo,para poder observar una mejor muestra de los datos que se encuentran en el dataframe y no solo los encabezados y la última parte se puede usar el método `sample()`. Si quiero que haya repetibilidad en mi aleatoriedad agregar el argumento `random_satet()` y establecer y algún valor entero de tu elección (cualquier número entero entre 0 y 4294967295)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encabezados\n",
    "print(data.head(10))\n",
    "\n",
    "## Parte final \n",
    "print(data.tail(10))\n",
    "\n",
    "## Aleatorio\n",
    "print(data.sample(10))\n",
    "\n",
    "## Aleatoriedad establecida\n",
    "print(data.sample(10, random_state= 1989))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `describe()` es muy útil para obtener información sobre las columnas numéricas de tus datos. La salida incluye estadísticas de resumen.   \n",
    "\n",
    "Es aconsejable que además, el análisis se acompañe de visualizaciones de datos para obtener una imagen completa, , ya que es posible que sus estructuras sean muy diferentes aunque tengan estadísticas resumidas similares (como el cuarteto de Anscombe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Método describe()\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera predeterminada, se ignoran las columnas no numéricas. Para poder incluir otro tipo de columnas no numéricas se utiliza el parámetro `include =` con el tipo de datos que queremos añadir p.e, `object` u añadir todas las columnas `all`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajar con valores duplicados y ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar valores ausentes\n",
    "Una buena manera de empezar a comprobar los valores ausentes es llamar al método `info()` de tu DataFrame. Los valores nulos son valores ausentes, mientras que los no nulos son valores no ausentes. \n",
    "\n",
    "Una vez identificado el número de observaciones podemos determinar el número de valores ausentes con `isna()`. Otra opción es con el método `value_counts()`, que devuelve la cantidad de veces que cada valor único aparece en esa columna. Este método es conveniente utilizarlo sobre una solo columna o *series*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determinar la información del dataframe\n",
    "data.info()\n",
    "\n",
    "## Contar el número de valores ausentes de cada columna\n",
    "data.isna().sum()\n",
    "\n",
    "## Contar el número de valores ausentes totales\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conocer el número de valores únicos para la columna source\n",
    "print(df_logs['source'].value_counts(dropna=False)) # drop_na=False permite contar el número de Nas en la columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida se ordena en orden descendente según el recuento de cada valor. Alternativamente, podemos ordenar la salida alfabéticamente según los nombres de los valores. Para hacerlo, podemos utilizar el método `sort_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ordenar el resultado de acuerdo con el index y no de acuerdo con los valores de la columna\n",
    "print(df_logs['source'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Dataframes con NaNs\n",
    "\n",
    "Para examinar las filas auseentes del dataframe, una de las maneras es utilizar el método `is.na()`.  El resultado genera una serie con los valores ausente `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtra los valores con NaNs\n",
    "print(df_logs[df_logs['source'].isna()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sin embargo a veces no es eso lo que nos convien. Para ello resulta más útil combinar `~ `con `isna()` para filtrar las filas con valores ausentes. La adición del símbolo de tilde (~), invierte el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtra los valores sin NaNs\n",
    "print(df_logs[~df_logs['source'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible filtrar un dataframe a partir de **múltiples condiciones de filtrado**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el df donde no haya valores ausentes en la columna \"email\" \n",
    "# y que solo sean valores de email de la columna source\n",
    "print(df_logs[(~df_logs['email'].isna()) & (df_logs['source'] == 'email')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de filtrado anterior consta de dos partes:\n",
    "\n",
    "1. `(~df_logs['email'].isna())` devuelve una serie de booleanos donde `True` indica que no falta ningún valor en la columna `'email'`.\n",
    "\n",
    "2. `(df_logs['source'] == 'email')` devuelve una serie de booleanos, donde `True` indica que `'source'` tiene `'email'` como valor, y `False` indica lo contrario.\n",
    "\n",
    "3. Comprobamos dos series de booleanos para ver dónde ambas condiciones devuelven `True`. Utilizamos el símbolo `&` para representar el operador lógico `and`. Las filas que cumplen ambas condiciones (es decir, que cumplen la primera condición y la segunda) se incluyen en el resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rellenar los valores categóricos ausentes\n",
    "\n",
    "Como recordatorio, las **variables categóricas** o **cualitativas** representan un conjunto de valores posibles que puede tener una observación particular. Es posible que tengan un orden en particular, por lo que serían **ordinales** o pueden no tener un orden en particular, por lo que serían **nominales**. \n",
    "\n",
    "Podemos sustituir los valores ausentes de las columnas con **valores por defecto** por ejemplo, una cadena vacía `''` . Esto lo podemos realizar con el método `fillna()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sustituir valores ausentes\n",
    "df_logs['email'] = df_logs[\"email\"].fillna(value= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar `fillna()` no es la única forma en que podemos rellenar los valores ausentes con cadenas vacías. También podemos hacerlo directamente al leer los datos mediante `read_csv()` utilizando el parámetro `keep_default_na = False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar el dataset haciendo que en vez de que sean NaN = TRUE sea FALSE\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "print(df_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Nota:</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Ten en cuenta que establecer `keep_default_na=False` convierte todos los valores ausentes **en cadenas vacías**, incluso para columnas numéricas. Esto hace que las columnas numéricas se lean como cadenas cuando tienen valores ausentes.   \n",
    "\n",
    "Así que asegúrate de usar solo `keep_default_na=False` cuando desees que todos los valores ausentes en cada columna se lean como cadenas vacías.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible que o no querramos sustituir los valores ausentes por algún valor de defecto o querramos sustituir los mismos por algún otro valor. En tal caso es útil emplear el método `replace()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remplazar el valor de defecto \"\" por otro valor\n",
    "df_logs['source'] = df_logs[\"source\"].replace(\"\", \"email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rellenar los valores ausentes cualitativos \n",
    "\n",
    "Como recordatorio, las variables **cuantitativas** tienen valores numéricos que podemos usar para cálculos aritméticos, por ejemplo, la altura, el peso, la edad y los ingresos. En Python, estos valores tienden a almacenarse como números enteros o flotantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data_no_nans_and_dupl.csv')\n",
    "\n",
    "df['category'] = df['category'].str.replace('tbc', 'baby care')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
